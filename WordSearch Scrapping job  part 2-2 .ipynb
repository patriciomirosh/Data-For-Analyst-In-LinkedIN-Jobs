{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "#If You dont have some of the below packages you have to install first.  pip install \"package\" \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import Packages\n",
    "#If You dont have some of the below packages you have to install first.  pip install \"package\" \n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aec7c19d",
   "metadata": {},
   "source": [
    "Obtaining the database where to extract the links to later extract the technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables to change in this part. We going to use the same path to chromeDriver and the list of tecnology waht we want to search in the body of propose jobs\n",
    "#path to CrhromeDriver\n",
    "pathToChromeDriver=r'C:\\Users\\patricio\\Downloads\\chromedriver_win32\\chromedriver.exe'\n",
    "#Tecnology and requirements list. If any of this words can be find in a compound word we try to search the word alone like this: ' SQL ','>SQL ',' SQL<'.        \n",
    "Tecnologies=['Power BI','Visme','Google Charts','Google Analytics','Ingles','Excel','Python',' SQL ','>SQL ',' SQL<','Big Data','MongoDB','NoSQL','PostgreSQL','MariaDB','Looker','AWS',\n",
    "             'English','Tableau','Qlik',\" R \",' R<',\">R \",'Julia','Microsoft Office','Pandas','Seaborn','Linux','Scrum','Jira','GitHub','Gitlab','Docker','Kubernetes','metodologías ágiles',\n",
    "             'Matplotlib','Machine Learning','Deep Learning','Keras','TensorFlow','Scikit learn','Plotly','NumPy','Bokeh','SciPy','Artificial Inteligence','inteligencia artificial',\n",
    "            'Kanban','Extreme Programming','Scala','business intelligence','business analyst', 'Access','MySQL',' SAP ','>SAP ',' SAP<','Power Point','Word']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this part we save the link\n",
    "service = Service(executable_path=pathToChromeDriver)\n",
    "#We use the same csv which created in the first part.\n",
    "#path to csv:\n",
    "DataFrameOfJobs=pd.read_csv(r'linkedinDate1002.csv')\n",
    "urllink=DataFrameOfJobs['link']\n",
    "\n",
    "DataFrameOfJobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a50ad",
   "metadata": {},
   "source": [
    "Database Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal part of the code, in this cell we extract the list technology and the count of every word in the list. this part going to every link\n",
    "#of the proposes jobs and will search the technology words in the technology list.\n",
    "finalListForDataframe= []\n",
    "for i in range(len(urllink)):\n",
    "    print(urllink[i].index)\n",
    "    Test = False\n",
    "    TecnologiesForDataFrame = {}\n",
    "    r = requests.get(urllink[i])\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    for Countator in Tecnologies:\n",
    "        try : \n",
    "            TecnologiesForDataFrame[Countator]= (str(soup.find(class_='show-more-less-html__button').parent.parent.section).lower()).count(Countator.lower())\n",
    "        except AttributeError:\n",
    "            DataFrameOfJobs=DataFrameOfJobs.drop(i)\n",
    "            Test = True\n",
    "            print('Different format or the propose dont acept solicitude anymore')\n",
    "            \n",
    "            break\n",
    "            \n",
    "    if Test == False:\n",
    "        finalListForDataframe.append(TecnologiesForDataFrame)  \n",
    "    \n",
    "#This part will be the slower part of the code. \"I add one script where we see if the code still running\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985083c6",
   "metadata": {},
   "source": [
    "Creacion del DataFramePrincipal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index of DataframeJobs\n",
    "index = []\n",
    "for i in range(len(DataFrameOfJobs)):\n",
    "    index.append(i)\n",
    "DataFrameOfJobs['index']= index\n",
    "DataFrameOfJobs.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98bd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(finalListForDataframe)\n",
    "DataFrameOfJobs=DataFrameOfJobs.set_index('index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e52f66e",
   "metadata": {},
   "source": [
    " ##### Clean data and appends to the tables####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750aec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['links']= DataFrameOfJobs['link']\n",
    "df['Title']= DataFrameOfJobs['title']\n",
    "df['Company']= DataFrameOfJobs['company']\n",
    "df['Place']= DataFrameOfJobs['JobPlace']\n",
    "df['Date']= DataFrameOfJobs['dateJob']\n",
    "\n",
    "df['R']= df[' R ']+df['>R ']+df[' R<']\n",
    "df=df.drop(columns=[' R ','>R ',' R<'])\n",
    "df['SQL']= df[' SQL ']+df['>SQL ']+df[' SQL<']\n",
    "df['SAP']= df[' SAP ']+df['>SAP ']+df[' SAP<']\n",
    "df=df.drop(columns=['>SQL ',' SQL<'])\n",
    "df=df.drop(columns=[' SAP ','>SAP ',' SAP<'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e8e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df ['test']=df.sum(axis=1)\n",
    "list(df['test']).count(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75809443",
   "metadata": {},
   "source": [
    "Tranformation and saved in the local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in local the Main DataFrame\n",
    "df.to_csv('linkedinDate1002.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9d74be",
   "metadata": {},
   "source": [
    "show the generated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd00c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df.groupby(['Company']).count().sort_values(by=['Title'],ascending=False                                               )\n",
    "#this code print the company with more job propose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcd514",
   "metadata": {},
   "source": [
    "Presents the number of jobs generated by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq['Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b8540",
   "metadata": {},
   "source": [
    "Transformo date a fecha.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "pd.options.display.max_rows = 180\n",
    "\n",
    "df=pd.read_csv('linkedinDate1002.csv')\n",
    "df=df.drop(columns='Unnamed: 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In  this part i change format of the date saved in the  Dataframe created previously. In this way we could use the new date as a datetime column\n",
    "pd.options.mode.chained_assignment = 'warn'\n",
    "actual_date = datetime.datetime.now()\n",
    "dates = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    datesContator = False\n",
    "    print(i)\n",
    "    time.sleep(0.01)\n",
    "    for week in range(5):\n",
    "        if f'{week} semana' in df.iloc[i]['Date']:\n",
    "            dates.append(actual_date - datetime.timedelta(weeks=week))\n",
    "            datesContator = True\n",
    "    for day in range(8):\n",
    "        if f'Hace {day} d' in df.iloc[i]['Date']:\n",
    "            dates.append(actual_date - datetime.timedelta(days=day))\n",
    "            datesContator = True\n",
    "    for month in range(13):\n",
    "        if f'{month} mes' in df.iloc[i]['Date']:\n",
    "            dates.append(actual_date - datetime.timedelta(days=30*month))\n",
    "            datesContator = True\n",
    "\n",
    "    for minutes in range(60):\n",
    "        if f'{minutes} minute' in df.iloc[i]['Date']:\n",
    "            dates.append(actual_date - datetime.timedelta(minutes=minutes))\n",
    "            datesContator = True\n",
    "    if datesContator == False:\n",
    "            dates.append(actual_date - datetime.timedelta(weeks=1))\n",
    "            print(i)\n",
    "            print(df.iloc[i]['Date'])\n",
    "print(f'{len(dates)},  {len(df)}')\n",
    "df['DatesTime']=dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9063e",
   "metadata": {},
   "source": [
    "#In the next part we created another csv where we going to save a dataframe with every technology if the program find more than word same in the \"job propose\" only save 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c6232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('linkedinDate1002.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce61acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "UniqueTecnology=df\n",
    "\n",
    "for column in UniqueTecnology.columns:\n",
    "    if column in ['Unnamed: 0','links','Title','Company','Place','Date','DatesTime','test']:\n",
    "        continue\n",
    "    for rows in range(len(UniqueTecnology)): \n",
    "        try:\n",
    "            if UniqueTecnology.iloc[rows][column] >=1:\n",
    "                UniqueTecnology.loc[rows, column] = 1\n",
    "        except:\n",
    "            print(UniqueTecnology.iloc[rows][column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this two csv are the two main csv for the data analyst , the first only count 1 for every tech requirement, and the second count the number of tomes the same technology requirement is repeated in the same offer.\n",
    "UniqueTecnology.to_csv('TabUniqueTecnology.csv')\n",
    "df.to_csv('TableauFinal.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d28a7c0d26f10b8bbd7fd9f7823cc0c2dabce89918bd027fd3f04f50fd2a81d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
